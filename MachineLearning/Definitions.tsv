Overfit 
Underfit    
feedforward neural  network is an artificial neural network wherein connections between the nodes do not form a cycle.
weight
Bias
Activation function nonlinear(cruved) maping to layers
Diferationable funciton that we can find its dirivitive
Activation Potential    lets us know weather to activate a neuron or not
optomizers  Update network weights iterative based in training data
Bias    is error due to erroneous or overly simplistic assumptions in the learning algorithm you’re using  This can lead to the model underfitting your data, making it hard for it to have high predictive accuracy and for you to generalize your knowledge from the training set to the test set
Variance     is error due to too much complexity in the learning algorithm you’re using. This leads to the algorithm being highly sensitive to high degrees of variation in your training data, which can lead your model to overfit the data. You’ll be carrying too much noise from your training data for your model to be very useful for your test data
ROC Curve   Reciever Operating characteristic graphical representation of the contrast between true positive rates and the false positive rate at various thresholds. It’s often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives).
Recall   is also known as the true positive rate: the amount of positives your model claims compared to the actual number of positives there are throughout the data.
Precision    also known as the positive predictive value, and it is a measure of the amount of accurate positives your model claims compared to the number of positives it actually claim
Naive Bayes     is considered “Naive” because it makes an assumption that is virtually impossible to see in real-life data: the conditional probability is calculated as the pure product of the individual probabilities of components. This implies the absolute independence of features — a condition probably never met in real life.
Type I error    is a false positive
Type II error   is a false negative
F1 score       is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst